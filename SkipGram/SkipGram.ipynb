{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I like dog i like cat i like animal dog cat animal apple cat dog like dog fish milk like dog \\\n",
    "cat eyes like i like apple apple i hate apple i movie book music like cat dog hate cat dog like\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 2 #词向量维度\n",
    "PRINT_EVERY = 1000 #可视化频率\n",
    "EPOCHS = 5000 #训练的轮数\n",
    "BATCH_SIZE = 5 #每一批训练数据大小\n",
    "N_SAMPLES = 3 #负样本大小\n",
    "WINDOW_SIZE = 5 #周边词窗口大小\n",
    "FREQ = 0 #词汇出现频率\n",
    "DELETE_WORDS = False #是否删除部分高频词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本预处理\n",
    "def preprocess(text, FREQ):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    #去除低频词\n",
    "    word_counts = Counter(words)\n",
    "    trimmed_words = [word for word in words if word_counts[word] > FREQ]\n",
    "    return trimmed_words\n",
    "words = preprocess(text, FREQ)\n",
    "\n",
    "#构建词典\n",
    "vocab = set(words)\n",
    "vocab2int = {w: c for c, w in enumerate(vocab)}\n",
    "int2vocab = {c: w for c, w in enumerate(vocab)}\n",
    "\n",
    "#将文本转化为数值\n",
    "int_words = [vocab2int[w] for w in words]\n",
    "\n",
    "#计算单词频次\n",
    "int_word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "word_freqs = {w: c/total_count for w, c in int_word_counts.items()}\n",
    "\n",
    "#去除出现频次高的词汇\n",
    "if DELETE_WORDS:\n",
    "    t = 1e-5\n",
    "    prob_drop = {w: 1-np.sqrt(t/word_freqs[w]) for w in int_word_counts}\n",
    "    train_words = [w for w in int_words if random.random()<(1-prob_drop[w])]\n",
    "else:\n",
    "    train_words = int_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#单词分布\n",
    "word_freqs = np.array(list(word_freqs.values()))\n",
    "unigram_dist = word_freqs / word_freqs.sum()\n",
    "noise_dist = torch.from_numpy(unigram_dist ** (0.75) / np.sum(unigram_dist ** (0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取目标词汇\n",
    "def get_target(words, idx, WINDOW_SIZE):\n",
    "    target_window = np.random.randint(1, WINDOW_SIZE+1)\n",
    "    start_point = idx-target_window if (idx-target_window)>0 else 0\n",
    "    \n",
    "    end_point = idx+target_window\n",
    "    targets = set(words[start_point:idx]+words[idx+1:end_point+1])\n",
    "   \n",
    "    return list(targets)\n",
    "\n",
    "#批次化数据\n",
    "def get_batch(words, BATCH_SIZE, WINDOW_SIZE):\n",
    "    n_batches = len(words)//BATCH_SIZE\n",
    "    words = words[:n_batches*BATCH_SIZE]\n",
    "    \n",
    "    for idx in range(0, len(words), BATCH_SIZE):\n",
    "        batch_x, batch_y = [],[]\n",
    "        batch = words[idx:idx+BATCH_SIZE]\n",
    "        \n",
    "        for i in range(len(batch)):\n",
    "            x = batch[i]\n",
    "            y = get_target(batch, i, WINDOW_SIZE)\n",
    "            batch_x.extend([x]*len(y))\n",
    "            batch_y.extend(y)\n",
    "            \n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramNeg(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_vocab, n_embed, noise_dist):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_vocab = n_vocab\n",
    "        self.n_embed = n_embed\n",
    "        self.noise_dist = noise_dist\n",
    "        \n",
    "        self.in_embed = nn.Embedding(n_vocab, n_embed)\n",
    "        self.out_embed = nn.Embedding(n_vocab, n_embed)\n",
    "        \n",
    "        self.in_embed.weight.data.uniform_(-1, 1)\n",
    "        self.out_embed.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    def forward_input(self, input_words):\n",
    "        input_vectors = self.in_embed(input_words)\n",
    "        return input_vectors\n",
    "    \n",
    "    def forward_output(self, output_words):\n",
    "        output_vectors = self.out_embed(output_words)\n",
    "        return output_vectors\n",
    "    \n",
    "    def forward_noise(self, size, N_SAMPLES):\n",
    "        noise_dist = self.noise_dist\n",
    "        \n",
    "        noise_words = torch.multinomial(noise_dist,\n",
    "                                       size * N_SAMPLES,\n",
    "                                       replacement=True)\n",
    "        \n",
    "        noise_vectors = self.out_embed(noise_words).view(size, N_SAMPLES, self.n_embed)   #noise_vectors:(batch_size, n_samples, n_embed)\n",
    "        \n",
    "        return noise_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
    "        \n",
    "        BATCH_SIZE, embed_size = input_vectors.shape\n",
    "        \n",
    "        input_vectors = input_vectors.view(BATCH_SIZE, embed_size, 1)\n",
    "        output_vectors = output_vectors.view(BATCH_SIZE, 1, embed_size)\n",
    "        \n",
    "        #target word, with shape :(batch_size, )\n",
    "        test = torch.bmm(output_vectors, input_vectors)                      \n",
    "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
    "        out_loss = out_loss.squeeze()\n",
    "        \n",
    "        #neg-sample words, with shape:()\n",
    "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
    "        noise_loss = noise_loss.squeeze().sum(1)\n",
    "        \n",
    "        return -(out_loss + noise_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(1.7248, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5398, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.8212, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.7078, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4962, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6824, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.7902, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4482, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4970, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4398, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.7940, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4665, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5476, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5610, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6509, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5790, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6149, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5857, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.3935, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4926, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6541, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6549, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6771, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4662, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5172, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4779, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5851, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6019, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4948, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4115, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5465, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6691, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.4889, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5772, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6286, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.7419, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5203, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.6741, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.5286, grad_fn=<NegBackward>)\n",
      "loss:  tensor(1.7527, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = SkipGramNeg(len(vocab2int), EMBEDDING_DIM, noise_dist=noise_dist)\n",
    "criterion = NegativeSamplingLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "steps = 0\n",
    "for e in range(EPOCHS):\n",
    "    \n",
    "    for input_words, target_words in get_batch(train_words, BATCH_SIZE, WINDOW_SIZE):\n",
    "        steps += 1\n",
    "        inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words)\n",
    "        \n",
    "        input_vectors = model.forward_input(inputs)\n",
    "        output_vectors = model.forward_output(targets)\n",
    "        size, _ = input_vectors.shape\n",
    "        noise_vectors = model.forward_noise(size, N_SAMPLES)\n",
    "        \n",
    "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
    "        \n",
    "        if steps % PRINT_EVERY == 0:\n",
    "            print(\"loss: \", loss)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, w in int2vocab.items():\n",
    "    vectors = model.state_dict()[\"in_embed.weight\"]\n",
    "    x,y = float(vectors[i][0]),float(vectors[i][1])\n",
    "    plt.scatter(x,y)\n",
    "    plt.annotate(w, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
